<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>Zheng (Jackie) Li Personal Page</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Zheng (Jackie) Li Personal Page">
<meta property="og:url" content="http://hsqmlzno1.github.io/index.html">
<meta property="og:site_name" content="Zheng (Jackie) Li Personal Page">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Zheng (Jackie) Li Personal Page">
  
    <link rel="alternative" href="/atom.xml" title="Zheng (Jackie) Li Personal Page" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <script src="/style.js"></script>
  

</head>

<body>
  <div id="container">
    <div class="left-col">
      <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img src="/assets/blogImg/me.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Zheng (Jackie) Li</a></h1>
		</hgroup>

		
		<p class="header-subtitle">zlict@connect.ust.hk</p>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">HOME</a></li>
	        
			</ul>
		</nav>
		<nav class="header-smart-menu">
	        
    		
    			
            
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/hsqmlzno1" title="github">github</a>
		        
					<a class="linkedin" target="_blank" href="https://www.linkedin.com/in/%E6%AD%A3-%E6%9D%8E-373956bb/" title="linkedin">linkedin</a>
		        
					<a class="google" target="_blank" href="https://scholar.google.com.hk/citations?user=P6fwn4AAAAAJ&hl=zh-CN" title="google">google</a>
		        
					<a class="weibo" target="_blank" href="#" title="weibo">weibo</a>
		        
					<a class="zhihu" target="_blank" href="#" title="zhihu">zhihu</a>
		        
					<a class="facebook" target="_blank" href="#" title="facebook">facebook</a>
		        
					<a class="twitter" target="_blank" href="#" title="twitter">twitter</a>
		        
					<a class="rss" target="_blank" href="#" title="rss">rss</a>
		        
			</div>
		</nav>
	</header>		
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"><i class="icon-list"></i></div>
  		<h1 class="header-author js-mobile-header hide">Zheng (Jackie) Li</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				
					<img src="/assets/blogImg/me.jpg" class="js-avatar">
				
			</div>
			<hgroup>
			  <h1 class="header-author">Zheng (Jackie) Li</h1>
			</hgroup>
			
			<p class="header-subtitle">zlict@connect.ust.hk</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">HOME</a></li>
		        
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/hsqmlzno1" title="github">github</a>
			        
						<a class="linkedin" target="_blank" href="https://www.linkedin.com/in/%E6%AD%A3-%E6%9D%8E-373956bb/" title="linkedin">linkedin</a>
			        
						<a class="google" target="_blank" href="https://scholar.google.com.hk/citations?user=P6fwn4AAAAAJ&hl=zh-CN" title="google">google</a>
			        
						<a class="weibo" target="_blank" href="#" title="weibo">weibo</a>
			        
						<a class="zhihu" target="_blank" href="#" title="zhihu">zhihu</a>
			        
						<a class="facebook" target="_blank" href="#" title="facebook">facebook</a>
			        
						<a class="twitter" target="_blank" href="#" title="twitter">twitter</a>
			        
						<a class="rss" target="_blank" href="#" title="rss">rss</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap">
        
  
    <article id="post-main" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><br></p>
<h2 id="About-me"><a href="#About-me" class="headerlink" title="About me"></a><font color="black" size="6">About me</font></h2><!--I am a Senior Applied Scientist from Amazon Search - [Rufus](https://www.aboutamazon.com/news/retail/amazon-rufus), working on LLM for shopping. 
-->
<p>I am a LLM post-training lead at Amazon Store Foundation Modeling team, working on post-training data, training paradigm (IFT/DPO/RL/Agentic), application, tooling and live traffic behavior alignment. We build ultra large-scale models (~100B Dense and X00B MoE) from scratch and customize it for shopping <a href="https://www.aboutamazon.com/news/retail/amazon-rufus" target="_blank" rel="external">Rufus</a>. I obtained my Ph.D. degree from HKUST CSE, under the supervision of Prof. <a href="http://www.cse.ust.hk/~qyang/" target="_blank" rel="external">Qiang Yang</a>. My research was grounded into various Amazon products and delivered significant improvements to conversational shopping (Rufus), e-commerce KG (COSMO), search query understanding, navigation, and discovery (A9), driving ~$0.84B revenues gains since 2021. </p>
<!--Previously, I worked in search Query Understanding ([QU](https://amazonsearchqu.github.io/)) team. I obtained my Ph.D. degree from the Department of Computer Science and Engineering, Hong Kong University of Science and Technology (HKUST). My supervisor is Prof. [Qiang Yang](http://www.cse.ust.hk/~qyang/). Before joining HKUST, I obtained the B.Eng degree from School of Data and Computer Science, Sun Yat-sen University (SYSU). [[Github]](https://github.com/hsqmlzno1)[[Google Scholar]](https://scholar.google.com/citations?user=P6fwn4AAAAAJ&hl=us)
--><!--[[Resume (out-of-date)]](/assets/ZhengLi_CV.pdf)-->
<!--**[Research internship positions)** in Amazon Store Foundation Modeling (Base: Bay area) are available. Feel free to send your CV to me if you are interested.
-->
<p><strong>Selected Projects</strong></p>
<ul>
<li><a href="https://www.aboutamazon.com/news/retail/amazon-rufus" target="_blank" rel="external">Rufus</a>: The first LLM-based Shopping Assistant in the world built from 0 to 1 (Founding Members)</li>
<li><a href="https://www.amazon.science/blog/building-commonsense-knowledge-graphs-to-aid-product-recommendation" target="_blank" rel="external">COSMO</a>: The world‚Äôs largest LLM-powered shopping KG from 0 to 1, grounded in Amazon Search. It won the 2024 Amazon‚Äôs Most Viewed Paper <a href="https://www.amazon.science/blog/the-10-most-viewed-publications-of-2024" target="_blank" rel="external">No.1</a> and Blog <a href="https://www.amazon.science/blog/the-10-most-viewed-blog-posts-of-2024" target="_blank" rel="external">No.5</a>. (Science Lead)</li>
<li><a href="https://www.aicrowd.com/challenges/amazon-kdd-cup-2024-multi-task-online-shopping-challenge-for-llms" target="_blank" rel="external">KDD Cup‚Äô24: LLMs for Shopping</a>, (Challenge Lead)</li>
<li><a href="https://www.aicrowd.com/challenges/amazon-kdd-cup-23-multilingual-recommendation-challenge" target="_blank" rel="external">KDD Cup‚Äô23: Multilingual Session-based Recommendation</a>(Challenge Co-Leads)</li>
<li>ACL 2023 Outstanding Paper Award</li>
</ul>
<h2 id="Research-interests"><a href="#Research-interests" class="headerlink" title="Research interests"></a><font color="black" size="6">Research interests</font></h2><!--My current research is Low-Resource Natural Language Processing (LR-NLP), including cross-lingual/multilingual, cross-domain, and multi-task scenarios, etc. Revolving around this goal, I mainly study the following topics:-->
<p>My current interest focus on building reliable and responsible Generative Foundation Models, specializing in <strong>Post-Training</strong> and its application:</p>
<ul>
<li>RLHF; E2E Agentic RL; Shopping Agent with Thinking; Constitutional RL; Live Traffic Behavior Alignment;</li>
<li>Supervised/Instruction Fine-Tuning; Synthetic Data Generation; LLM Application \&amp; Evaluation.</li>
</ul>
<!--* **Natural Language Processing**: large language models (LLMs) & multi-modality (vision foundation model), instruction following/tuning, Knowledge graph, information extraction, question answering, sentiment analysis.
* **Machine Learning**: transfer Learning, meta-learning, semi/weakly-supervised learning, multi-task learning, graph embedding.
-->
<h2 id="Experiences"><a href="#Experiences" class="headerlink" title="Experiences"></a><font color="black" size="6">Experiences</font></h2><!--* **2016-present**, Ph.D. student, **The Hong Kong University of Science and Technology**, Computer Science and Engineering Department. Supervisor: Prof. [Qiang Yang](http://www.cse.ust.hk/~qyang/)
* **2012-2016**, B.Eng., **Sun Yat-sen Universit**y, School of Data and Computer Science.
</br>-->
<ul>
<li><strong>2020-Present</strong>, <strong>Amazon Search (A9)</strong>, Senior Applied Scientist, Bay Area, USA.</li>
<li><strong>Jun 2020-Sep 2020</strong>, <strong>Google Research</strong>, Research intern, NLX Group, Mountain View, CA, USA. Host: Ji Young Lee</li>
<li><strong>Seq 2019-Dec 2019</strong>, <strong>Amazon Search (A9)</strong>, Applied scientist intern, Search and NLP group, Palo, Alto, CA, USA. Research topic: Meta Learning, Cross-lingual transfer. Host: Bing Yin</li>
<li><strong>Jun 2016-Aug 2016</strong>, <strong>HKUST Fok Ying Tung Research</strong>, Research intern, Host, Prof. Qiang Yang</li>
<li><strong>Jul 2015-Oct 2015</strong>, <strong>Microsoft Research Asia (MSRA)</strong>, Research intern, Multimedia Search and Mining Group. Host: Dr. Tao Mei</li>
</ul>
<h2 id="News"><a href="#News" class="headerlink" title="News"></a><font color="black" size="6">News</font></h2><ul>
<li>Oct 2025 - I will serve Area Chair for ICLR 2026.</li>
<li>Oct 2025 - I will serve SPC for AAAI 2026.</li>
<li>Aug 2025 - Three paper were accepted by EMNLP 2025.</li>
<li>Aug 2025 - One paper were accepted by COLM 2025.</li>
<li>May 2025 - Two paper were accepted by ACL 2025.</li>
<li>Jan 2025 - Two paper were accepted by NAACL 2025.</li>
<li>Jan 2025 - One paper was accepted by <strong>Nature Reviews Bioengineering</strong>.</li>
<li>Dec 2024 - Our COSMO [<a href="https://assets.amazon.science/1a/a6/44a84fa24574979b066037b4e20b/cosmo-a-large-scale-e-commerce-common-sense-knowledge-generation-and-serving-system-at-amazon.pdf" target="_blank" rel="external">paper</a>] and [<a href="https://www.amazon.science/blog/building-commonsense-knowledge-graphs-to-aid-product-recommendation" target="_blank" rel="external">blog</a>] ranks the 1st and 5th in the [<a href="https://www.amazon.science/blog/the-10-most-viewed-publications-of-2024" target="_blank" rel="external">10-most-viewed-publications-of-2024</a>] and [<a href="https://www.amazon.science/blog/the-10-most-viewed-blog-posts-of-2024" target="_blank" rel="external">10-most-viewed-blog-posts-of-2024</a>] for Amazon, respectively.</li>
<li>Oct 2024 - One paper was accepted by NeurIPS 2024.</li>
<li>Sep 2024 - Four papers were accepted by EMNLP 2024.</li>
<li>May 2024 - Two papers were accepted by ICML 2024.</li>
<li>May 2024 - One paper was accepted by KDD 2024.</li>
<li>May 2024 - One paper was accepted by ACL 2024.</li>
<li>April 2024 - One paper was accepted by NAACL 2024.</li>
<li>March 2024 - We are hosting the <strong>üõçÔ∏èAmazon KDD Cup 2024: Multi-Task Online Shopping Challenge for LLMs</strong> with plenty of awards. Click <a href="https://www.aicrowd.com/challenges/amazon-kdd-cup-2024-multi-task-online-shopping-challenge-for-llms" target="_blank" rel="external">here</a> to contribute ingenious solutions üöÄ!</li>
<li>Jan 2024 - One paper was accepted by SIGMOD 2024.</li>
<li>Jan 2024 - One paper was accepted by WWW 2024.</li>
</ul>
<!--* Dec 2023 - One survey paper about [LLMs in Medicine](https://arxiv.org/pdf/2311.05112.pdf) was in Arxiv now.
* Oct 2023 - Two papers were accepted by EMNLP 2023.
* Sep 2023 - Two papers were accepted by NeurIPS 2023, one for our KDD Cup'23 benchmark dataset paper, and one for session-based recommendation.
* June 2023 - Our paper "[SCOTT](https://arxiv.org/pdf/2305.01879.pdf)" has been selected for <font color=red>ACL 2023 Outstanding Paper Award </font>
* June 2023 - Invited to serve as Senoir Program Committee (SPC) for AAAI 2024.
* May 2023 - One paper was accepted by KDD 2023.
* Jan 2023 - Four papers were accepted by ACL 2023.
* **We have launched the [Amazon KDD Cup'23 Competition](https://www.aicrowd.com/challenges/amazon-kdd-cup-23-multilingual-recommendation-challenge), featuring a multilingual recommendation challenge. Feel free to submit your solutions and potentially win thousands of dollars!**-->
<!--* Jan 2023 - One paper was accepted by WWW 2023.
* Jan 2023 - One paper was accepted by ICLR 2023.-->
<!--* July 2022 - Invited to serve as Program Committee for KDD 2023.
* Sep 2022 - One paper was accepted by EMNLP-Finding 2022.
* Sep 2022 - One paper was accepted by NeurIPS 2022.
* Sep 2022 - [**[WWW 2022]**](https://arxiv.org/pdf/2202.06129.pdf) We released the [[code]](https://github.com/amzn/rete-thewebconf-2022) for sequential query and product joint recommendation.
* Aug 2022 - [**[ACL 2022]**](https://assets.amazon.science/06/8b/696eef0f4b66bc93543a20ff41ff/multilingual-knowledge-graph-completion-with-self-supervised-adaptive-graph-alignment.pdf) We released the E-commerce Product KG [[data]](https://github.com/amzn/ss-aga-kgc) and [[code]](https://github.com/amzn/ss-aga-kgc)  for multilingual KGC.
* Aug 2022 - [**[KDD 2022]**](https://arxiv.org/pdf/2206.07746.pdf) We released the [[code]](https://github.com/amazon-research/DosCond) for graph condensation.
* Aug 2022 - [**[NAACL 2022]**](https://arxiv.org/pdf/2205.10471.pdf) We released the [[academic]](https://github.com/Yifan-Gao/multilingual_keyphrase_generation) and the [[e-commerce]](https://github.com/amzn/multilingual-keyphrase-generation/tree/main/data/e-commerce) multilingual keyphrase generation datasets, along with the [[code](https://github.com/amzn/multilingual-keyphrase-generation)].
* July 2022 - Invited to serve as Senoir Program Committee (SPC) for AAAI 2023.
-->
<!--* July 2022 - Invited to serve as Program Committee for EMNLP 2022.
* July 2022 - One paper was accepted by RecSys (Industry Track) 2022.
* Apr 2022 - One long paper was accepted by KDD (Research Track) 2022.
* Jan 2022 - Invited to serve as Program Committee for NeurIPS 2022.
* Apr 2022 - One long paper was accepted by NAACL-Finding 2022.
* Feb 2022 - One long paper was accepted by ACL 2022.
* Jan 2022 - One long paper was accepted by WWW 2022.
* Jan 2022 - Invited to serve as Program Committee for ICML 2022.
* Jan 2022 - Invited to serve as Program Committee for IJCAI 2022.
-->
<!--* Nov 2021 - Invited to serve as Program Committee for KDD 2022.
* Nov 2021 - Invited to serve as Reviewer for ACL 2022 Rolling review.
* Aug 2021 - One long paper was accepted by EMNLP 2021.
* Jun 2021 - Invited to serve as Program Committee for AAAI 2022.
* Aug 2021 - One long paper was accepted by CIKM 2021 (Industry track).
* Jun 2021 - Invited to serve as Program Committee for ICLR 2022.
* April 2021 - Invited to serve as Program Committee for NeurIPS 2021.
* Mar 2021 - Invited to serve as Program Committee for EMNLP 2021.
-->
<h2 id="Publications-Google-Scholar"><a href="#Publications-Google-Scholar" class="headerlink" title="Publications [Google Scholar]"></a><font color="black" size="6">Publications</font> [<font color="CornflowerBlue" size="5"><a href="https://scholar.google.com/citations?user=P6fwn4AAAAAJ&amp;hl=us" target="_blank" rel="external">Google Scholar</a></font>]</h2><p>(* denotes equal contributions, # denotes the corresponding author, + denotes interns/students i mentored)</p>
<p><strong>2025</strong></p>
<ul>
<li><strong><font size="3">Application of Large Language Models in Medicine</font></strong> [<a href="https://www.nature.com/articles/s44222-025-00279-5" target="_blank" rel="external">pdf</a>][<a href="https://github.com/AI-in-Health/MedLLMsPracticalGuide" target="_blank" rel="external">github</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Hongjian Zhou+, Fenglin Liu+, <strong>Zheng Li#</strong>, Jiebo Luo, David A. Clifton (<strong>Nature Reviews Bioengineering 2025</strong>)<br></font></li>
</ul>
<ul>
<li><p><strong><font size="3">Aligning Large Language Models with Implicit Preferences from User-Generated Content</font></strong> [<a href="https://aclanthology.org/2025.acl-long.384.pdf" target="_blank" rel="external">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Zhaoxuan Tan+, <strong>Zheng Li#</strong>, et al.(<strong>ACL 2025</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">UniConv: Unifying Retrieval and Response Generation for Large Language Models in Conversations</font></strong> [<a href="https://arxiv.org/pdf/2507.07030" target="_blank" rel="external">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Fengran Mo+, Yifan Gao, Chuan Meng, Xin Liu, Zhuofeng Wu, Kelong Mao, Zhengyang Wang, Pei Chen, <strong>Zheng Li</strong>, Xian Li, Bing Yin, Meng Jiang (<strong>ACL 2025</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">DrAgent: Empowering Large Language Models as Medical Agents for Multi-hop Medical Reasoning</font></strong> [<a href="https://openreview.net/pdf?id=7VrpJBazPL" target="_blank" rel="external">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Fenglin Liu+, <strong>Zheng Li#</strong>, et al. (<strong>EMNLP 2025</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Can Language Models Follow Multiple Turns of Entangled Instructions?</font></strong> [<a href="">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Chi Han+, Xin Liu, Haodong Wang, Shiyang Li, Jingfeng Yang, Haoming Jiang, Zhengyang Wang, Qingyu Yin, Liang Qiu, Changlong Yu, Yifan Gao, <strong>Zheng Li</strong>, Bing Yin, Jingbo Shang, Heng Ji (<strong>EMNLP 2025</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">GRIL: Knowledge Graph Retrieval-Integrated Learning with Large Language Models</font></strong> [<a href="https://openreview.net/pdf?id=wmSP2lVDdj" target="_blank" rel="external">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Jialin Chen+, Houyu Zhang, Seongjun Yun, Alejandro Mottini, Rex Ying, Xiang song, Vassilis N. Ioannidis, <strong>Zheng Li</strong>, Qingjun Cui (<strong>EMNLP 2025</strong>)<br></font></p>
</li>
</ul>
<ul>
<li><strong><font size="3">Self-Rewarding PPO: Aligning Large Language Models with Demonstrations Only</font></strong> [<a href="">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Qingru Zhang+, Liang Qiu, Ilgee Hong, Zhenghao Xu, Tianyi Liu, Shiyang Li, Rongzhi Zhang, <strong>Zheng Li</strong>, Lihong Li, Bing Yin, Chao Zhang, Jianshu Chen, Haoming Jiang, Tuo Zhao (<strong>COLM 2025</strong>)<br></font></li>
</ul>
<ul>
<li><p><strong><font size="3">Hephaestus: Improving Fundamental Agent Capabilities of Large Language Models through Continual Pre-Training</font></strong> [<a href="https://arxiv.org/pdf/2502.06589" target="_blank" rel="external">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"> Yuchen Zhuang, Jingfeng Yang, Haoming Jiang, Xin Liu, Kewei Cheng, Sanket Lokegaonkar, Yifan Gao, Qing Ping, Tianyi Liu, Binxuan Huang, <strong>Zheng Li</strong>, Zhengyang Wang, Pei Chen, Ruijie Wang, Rongzhi Zhang, Nasser Zalmout, Priyanka Nigam, Bing Yin, Chao Zhang (<strong>NAACL 2025</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">IHEval: Evaluating Language Models on Following the Instruction Hierarchy</font></strong> [<a href="https://assets.amazon.science/22/57/ad173f7f449eadaaa7cd05491585/iheval-evaluating-language-models-on-following-the-instruction-hierarchy.pdf" target="_blank" rel="external">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"> Zhihan Zhang, Shiyang Li, Zixuan Zhang, Xin Liu, Haoming Jiang, Xianfeng Tang, Yifan Gao, <strong>Zheng Li</strong>, Haodong Wang, Zhaoxuan Tan, Yichuan Li, Qingyu Yin, Bing Yin, Meng Jiang (<strong>NAACL 2025</strong>)<br></font></p>
</li>
</ul>
<p><strong>2024</strong></p>
<ul>
<li><p><strong><font size="3">Shopping MMLU: A Massive Multi-Task Online Shopping Benchmark for Large Language Models</font></strong> [<a href="https://openreview.net/pdf?id=D3jyWDBZTk" target="_blank" rel="external">pdf</a>][<a href="https://github.com/KL4805/ShoppingMMLU" target="_blank" rel="external">code &amp; data</a>][<a href="https://huggingface.co/spaces/KL4805/shopping_mmlu_leaderboard" target="_blank" rel="external">leaderboard</a>][<a href="https://amazon-kddcup24.github.io/" target="_blank" rel="external">workshop</a>][<a href="https://www.aicrowd.com/challenges/amazon-kdd-cup-2024-multi-task-online-shopping-challenge-for-llms" target="_blank" rel="external">competition</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Yilun Jin+#, <strong>Zheng Li</strong>#, Chenwei Zhang, et al (<strong>NeurIPS 2024, <font color="red">our KDD Cup‚Äô24 benchmark paper</font></strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Evolutionary Contrastive Distillation for Language Model Alignment</font></strong> [<a href="https://aclanthology.org/2024.findings-emnlp.307.pdf" target="_blank" rel="external">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"> Julian Katz-Samuels#, <strong>Zheng Li</strong>#, Hyokun Yun#, Priyanka Nigam, Yi Xu, Vaclav Petricek, Bing Yin, Trishul Chilimbi (<strong>EMNLP 2024</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark</font></strong> [<a href="https://aclanthology.org/2024.emnlp-main.759.pdf" target="_blank" rel="external">pdf</a>][<a href="https://github.com/AI-in-Health/ClinicBench" target="_blank" rel="external">code</a>][<a href="https://huggingface.co/spaces/fenglinliu/medical_llm_leaderboard" target="_blank" rel="external">leaderboard</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Fenglin Liu+, <strong>Zheng Li</strong>#, et al (<strong>EMNLP 2024</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">IntentionQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Large Language Models in E-commerce</font></strong> [<a href="https://aclanthology.org/2024.findings-emnlp.123.pdf" target="_blank" rel="external">pdf</a>][<a href="https://github.com/HKUST-KnowComp/IntentionQA" target="_blank" rel="external">code</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"> Wenxuan Ding, Weiqi Wang, Sze Heng Douglas Kwok, Minghao Liu, Tianqing Fang, Jiaxin Bai, Xin Liu, Changlong Yu, <strong>Zheng Li</strong>, Chen Luo, Qingyu Yin, Bing Yin, Junxian He, Yangqiu Song (<strong>EMNLP 2024</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding</font></strong> [<a href="https://aclanthology.org/2024.emnlp-main.446.pdf" target="_blank" rel="external">pdf</a>][<a href="https://github.com/HKUST-KnowComp/MIND_Distillation" target="_blank" rel="external">code</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"> Baixuan Xu, Weiqi Wang, Haochen Shi, Wenxuan Ding, Huihao Jing, Tianqing Fang, Jiaxin Bai, Xin Liu, Changlong Yu, <strong>Zheng Li</strong>, Chen Luo, Qingyu Yin, Bing Yin, Long Chen, Yangqiu Song (<strong>EMNLP 2024</strong>)<br></font></p>
</li>
</ul>
<ul>
<li><p><strong><font size="3">COSMO: A Large-Scale E-commerce Common Sense Knowledge Generation and Serving System at Amazon</font></strong> [<a href="https://assets.amazon.science/1a/a6/44a84fa24574979b066037b4e20b/cosmo-a-large-scale-e-commerce-common-sense-knowledge-generation-and-serving-system-at-amazon.pdf" target="_blank" rel="external">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Changlong Yu*+, Xin Liu*+,‚Ä¶, <strong>Zheng Li*#</strong> (<strong>SIGMOD 2024</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Language Models As Semantic Indexers</font></strong> [<a href="https://arxiv.org/pdf/2310.07815.pdf" target="_blank" rel="external">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"> Bowen Jin+, Hansi Zeng, Guoyin Wang, Xiusi Chen, Tianxin Wei, Ruirui Li, Zhengyang Wang, <strong>Zheng Li</strong>, Yang Li, Hanqing Lu, Suhang Wang, Jiawei Han, Xianfeng Tang (<strong>ICML 2024</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">MEMORYLLM: Toward Self-Updating Large Language Models</font></strong> [<a href="">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"> Yu Wang+, Yifan Gao, Xiusi Chen, Haoming Jiang, Shiyang Li, Jingfeng Yang, Qingyu Yin, <strong>Zheng Li</strong>, Xian Li, Bing Yin, Jingbo Shang, Julian McAuley (<strong>ICML 2024</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs</font></strong> [<a href="https://arxiv.org/pdf/2404.07103" target="_blank" rel="external">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"> Bowen Jin+, Chulin Xie, Jiawei Zhang, Kashob Kumar Roy, Yu Zhang, <strong>Zheng Li</strong>, Ruirui Li, Xianfeng Tang, Suhang Wang, Yu Meng, Jiawei Han (<strong>ACL 2024</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">IterAlign: Iterative Constitutional Alignment of Large Language Models</font></strong> [<a href="https://arxiv.org/pdf/2403.18341" target="_blank" rel="external">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"> Xiusi Chen, Hongzhi Wen, Sreyashi Nag, Chen Luo, Qingyu Yin, Ruirui Li, <strong>Zheng Li</strong>, Wei Wang (<strong>NAACL 2024</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Understanding Inter-Session Intentions via Complex Logical Reasoning</font></strong> [<a href="https://arxiv.org/pdf/2312.13866.pdf" target="_blank" rel="external">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"> Jiaxin Bai+, Chen Luo, <strong>Zheng Li</strong>, Qingyu Yin, Yangqiu Song (<strong>KDD 2024</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Hierarchical Query Classification in E-commerce Search</font></strong> [<a href="https://arxiv.org/pdf/2403.06021" target="_blank" rel="external">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Bing He+, Sreyashi Nag, Limeng Cui, Suhang Wang, <strong>Zheng Li</strong>, Rahul Goutam, Zhen Li, Haiyang Zhang (<strong>WWW 2024</strong>)<br></font></p>
</li>
</ul>
<p><strong>2023</strong></p>
<ul>
<li><p><strong><font size="3">Amazon-M2: A Multilingual Multi-locale Shopping Session Dataset for Recommendation and Text Generation</font></strong> [<a href="https://arxiv.org/pdf/2307.09688.pdf" target="_blank" rel="external">pdf</a>][<a href="https://www.aicrowd.com/challenges/amazon-kdd-cup-23-multilingual-recommendation-challenge" target="_blank" rel="external">KDD Cup website</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Wei Jin+, Haitao Mao, <strong>Zheng Li</strong>,‚Ä¶,Xianfeng Tang (<strong>NeurIPS 2023, <font color="red">our KDD Cup‚Äô23 benchmark paper</font></strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Enhancing User Intent Capture in Session-Based Recommendation with Attribute Patterns</font></strong> [<a href="https://arxiv.org/pdf/2312.16199.pdf" target="_blank" rel="external">pdf</a>][<a href="">code</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Xin Liu+, <strong>Zheng Li#</strong>, Yifan Gao, Jingfeng Yang, Tianyu Cao, Zhengyang Wang, Bing Yin, Yangqiu Song (<strong>NeurIPS 2023</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Mutually-paced Knowledge Distillation for Cross-lingual Temporal Knowledge Graph Reasoning</font></strong> [<a href="https://arxiv.org/pdf/2303.14898.pdf" target="_blank" rel="external">pdf</a>][<a href="">code</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Ruijie Wang+, <strong>Zheng Li#</strong>, Jingfeng Yang, Tianyu Cao, Bing Yin, Tarek Abdelzaher (<strong>WWW 2023</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">SCOTT: Self-Consistent Chain-of-Thought Distillation</font></strong> [<a href="https://arxiv.org/pdf/2305.01879.pdf" target="_blank" rel="external">pdf</a>][<a href="">code</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Peifeng Wang+, Zhengyang Wang, <strong>Zheng Li#</strong>, Yifan Gao, Bing Yin, Xiang Ren (<strong><font color="red">ACL 2023, Outstanding Paper Award</font></strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Multimodal Prompt Learning for Product Title Generation with Extremely Limited Labels</font></strong> [<a href="https://aclanthology.org/2023.findings-acl.166.pdf" target="_blank" rel="external">pdf</a>][code]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Fenglin Liu+, Bang Yang, <strong>Zheng Li#</strong>, Qingyu Yin, Chenyu You, Xuewei Ma, Bing Yin and Yuexian Zou  (<strong>ACL 2023</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">FolkScope: Intention Knowledge Graph Construction for E-commerce  Commonsense Discovery</font></strong> [<a href="https://arxiv.org/pdf/2211.08316.pdf" target="_blank" rel="external">pdf</a>][<a href="">code</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Changlong Yu+, Weiqi Zhang, Xin Liu+, Jiaxin Bai+, Yangqiu Song, <strong>Zheng Li</strong>, Yifan Gao, Tianyu Cao, Bing Yin,  (<strong>ACL 2023</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Graph Reasoning for Question Answering with Triplet Retrieval</font></strong> <a href="https://arxiv.org/pdf/2305.18742.pdf" target="_blank" rel="external">pdf</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Shiyang Li+, Yifan Gao, Haoming Jiang, Qingyu Yin, <strong>Zheng Li</strong>, Xifeng Yan, Chao Zhang and Bing Yin  (<strong>ACL 2023</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Improving Consistency for Text Summarization with Energy Functions</font></strong> [<a href="https://aclanthology.org/2023.findings-emnlp.798.pdf" target="_blank" rel="external">pdf</a>][<a href="https://github.com/pkuzengqi/EnergySum" target="_blank" rel="external">code</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"> Qi Zeng, Qingyu Yin, <strong>Zheng Li</strong>, Yifan Gao, Sreyashi Nag, Zhengyang Wang, Bing Yin, Heng Ji, Chao Zhang(<strong>EMNLP 2023</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Knowledge-Selective Pretraining for Attribute Value Extraction</font></strong> [<a href="https://aclanthology.org/2023.findings-emnlp.542.pdf" target="_blank" rel="external">pdf</a>][<a href="">code</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"> Hui Liu, Qingyu Yin, Zhengyang Wang, Chenwei Zhang, Haoming Jiang, Yifan Gao, <strong>Zheng Li</strong>, Xian Li, Chao Zhang, Bing Yin, William Yang Wang, Xiaodan Zhu (<strong>EMNLP 2023</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Knowledge graph reasoning over entities and numerical values</font></strong> [<a href="https://arxiv.org/pdf/2306.01399.pdf" target="_blank" rel="external">pdf</a>][<a href="">code</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"> Jiaxin Bai, Chen Luo, <strong>Zheng Li</strong>, Qingyu Yin, Bing Yin, Yangqiu Song (<strong>KDD 2023</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">HomoDistil: Homotopic Task-Agnostic Distillation of Pre-trained Transformers</font></strong> [<a href="https://openreview.net/pdf?id=1LmgISIDZJ" target="_blank" rel="external">pdf</a>][<a href="">code</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Chen Liang+, Haoming Jiang, <strong>Zheng Li</strong>, Xianfeng Tang, Bing Yin, Tuo Zhao (<strong>ICLR 2023</strong>)<br></font></p>
</li>
</ul>
<p><strong>2022</strong></p>
<ul>
<li><p><strong><font size="3">Learning to Sample and Aggregate: Few-shot Reasoning over Temporal Knowledge Graph</font></strong> [<a href="https://openreview.net/pdf?id=1LmgISIDZJ" target="_blank" rel="external">pdf</a>][<a href="">code</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Ruijie Wang+, <strong>Zheng Li#</strong>, Dachun Sun, Shengzhong Liu, Jinning Li, Bing Yin, Tarek Abdelzaher (<strong>NeurIPS 2022</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Multilingual Knowledge Graph Completion with Self-Supervised Adaptive Graph Alignment</font></strong> [<a href="https://assets.amazon.science/06/8b/696eef0f4b66bc93543a20ff41ff/multilingual-knowledge-graph-completion-with-self-supervised-adaptive-graph-alignment.pdf" target="_blank" rel="external">pdf</a>][<a href="https://github.com/amzn/ss-aga-kgc" target="_blank" rel="external">code</a>][<a href="https://github.com/amzn/ss-aga-kgc" target="_blank" rel="external">data</a>][<a href="https://mp.weixin.qq.com/s/S4Wcn-WiIXyzmCZxLGY2lw" target="_blank" rel="external">media</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Zijie Huang+, <strong>Zheng Li#</strong>, Haoming Jiang, Tianyu Cao, Hanqing Lu, Bing Yin, Karthik Subbian, Yizhou Sun, Wei Wang (<strong>ACL 2022, Long paper</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">RETE: Retrieval-Enhanced Temporal Event Forecasting on Unified Query Product Evolutionary Graph</font></strong> [<a href="https://arxiv.org/pdf/2202.06129.pdf" target="_blank" rel="external">pdf</a>][<a href="https://github.com/amzn/rete-thewebconf-2022" target="_blank" rel="external">code</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Ruijie Wang+, <strong>Zheng Li#</strong>, Danqing Zhang, Qingyu Yin, Tong Zhao, Bing Yin and Tarek Abdelzaher (<strong>WWW 2022, Long paper, Research track</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Disentangling Task Relations for Few-shot Text Classification via Self-Supervised Hierarchical Task Clustering</font></strong> [<a href="https://arxiv.org/pdf/2211.08588.pdf" target="_blank" rel="external">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Juan Zha*, <strong>Zheng Li*</strong>, Ying Wei and Yu Zhang (<strong>EMNLP 2022, Long paper</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Retrieval-Augmented Multilingual Keyphrase Generation with Retriever-Generator Iterative Training</font></strong> [<a href="https://arxiv.org/pdf/2205.10471.pdf" target="_blank" rel="external">pdf</a>][<a href="https://github.com/amzn/multilingual-keyphrase-generation" target="_blank" rel="external">code</a>][<a href="https://github.com/Yifan-Gao/multilingual_keyphrase_generation" target="_blank" rel="external">academic data</a>][<a href="https://github.com/amzn/multilingual-keyphrase-generation/tree/main/data/e-commerce" target="_blank" rel="external">e-commerce data</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Yifan Gao+, Qingyu Yin#, <strong>Zheng Li#</strong>, Rui Meng, Tong Zhao, Bing Yin, Irwin King, Michael Lyu (<strong>NAACL 2022, Long paper</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Condensing Graphs via One-Step Gradient Matching</font></strong> [<a href="https://arxiv.org/pdf/2206.07746.pdf" target="_blank" rel="external">pdf</a>][<a href="https://github.com/amazon-research/DosCond" target="_blank" rel="external">code</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Wei Jin+, Xianfeng Tang, Haoming Jiang, <strong>Zheng Li</strong>, Danqing Zhang, Jiliang Tang, Bin Yin (<strong>KDD 2022, Long paper, Research Track</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Query Attribute Recommendation at Amazon Search</font></strong> [<a href="https://dl.acm.org/doi/abs/10.1145/3523227.3547395" target="_blank" rel="external">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Chen Luo, William Headean, Neela Avudaiappan, Haoming Jiang, Tianyu Cao, Qingyu Yin, Yifan Gao, <strong>Zheng Li</strong>, Rahul Goutam, Haiyang Zhang, Bing Yin (<strong>RecSys 2022, Industry Track</strong>)<br></font></p>
</li>
</ul>
<p><strong>2021 &amp; Before</strong></p>
<ul>
<li><p><strong><font size="3">Meta Teacher Student Network for Multilingual Sequence Labeling with Minimal Supervision</font></strong> [<a href="https://aclanthology.org/2021.emnlp-main.255.pdf" target="_blank" rel="external">pdf</a>][<a href="https://github.com/amzn/x-metats" target="_blank" rel="external">code</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"><strong>Zheng Li</strong>, Danqing Zhang, Tianyu Cao, Yiwei Song, Bing Yin (<strong>EMNLP 2021, Long paper, poster</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">QUEACO: Borrowing Treasures from Weakly-labeled Behavior Data for Query Attribute Value Extraction</font></strong> [<a href="https://arxiv.org/pdf/2108.08468.pdf" target="_blank" rel="external">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Danqing Zhang*, <strong>Zheng Li*</strong>, Tianyu Cao, Chen Luo, Tony Wu, Hanqing Lu, Yiwei Song, Bing Yin, Tuo Zhao, Qiang Yang (<strong>CIKM 2021, Long paper, Applied science track.</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Learn to Cross-lingual Transfer with Meta Graph Learning Across Heterogeneous Languages</font></strong> [<a href="/assets/publications/EMNLP2020.pdf">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"><strong>Zheng Li</strong>, Mukul Kumar, William Headden, Bing Yin, Ying Wei, Yu Zhang, Qiang Yang (<strong>EMNLP 2020, Long paper, oral</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Transferable End-to-End Aspect-based Sentiment Analysis with Selective Adversarial Learning</font></strong> [<a href="/assets/publications/SAL2019.pdf">pdf</a>][<a href="/assets/slides/SAL_EMNLP19.pdf">slides</a>][<a href="https://github.com/hsqmlzno1/Transferable-E2E-ABSA" target="_blank" rel="external">code</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"><strong>Zheng Li</strong>, Xin Li, Ying Wei, Lidong Bing, Yu Zhang, Qiang Yang (<strong>EMNLP 2019, Long paper, oral</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Exploiting Coarse-to-Fine Task Transfer for Aspect-level Sentiment Classification</font></strong> [<a href="/assets/publications/MGAN2019.pdf">pdf</a>][<a href="/assets/slides/MGAN_AAAI19.pptx">slides</a>][<a href="https://github.com/hsqmlzno1/MGAN" target="_blank" rel="external">data</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"><strong>Zheng Li</strong>, Ying Wei, Yu Zhang, Xiang Zhang, Xin Li, Qiang Yang (<strong>AAAI 2019, oral</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Hierarchical Attention Transfer Network for Cross-domain Sentiment Classification</font></strong> [<a href="/assets/publications/HATN2018.pdf">pdf</a>][<a href="/assets/slides/AAAI_slides.pptx">slides</a>][<a href="https://github.com/hsqmlzno1/HATN" target="_blank" rel="external">code</a>][<a href="/assets/video/hatn_visualization.mp4">demo</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"><strong>Zheng Li</strong>, Ying Wei, Yu Zhang, Qiang Yang (<strong>AAAI 2018, oral</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">End-to-End Adversarial Memory Network for Cross-domain Sentiment Classification</font></strong> [<a href="/assets/publications/AMN2017.pdf">pdf</a>][<a href="/assets/slides/IJCAI_slides.pptx">slides</a>][<a href="https://github.com/hsqmlzno1/HATN" target="_blank" rel="external">code</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"><strong>Zheng Li</strong>, Yu Zhang, Ying Wei, Yuxiang Wu, Qiang Yang (<strong>IJCAI 2017, oral</strong>)<br></font></p>
</li>
<li><p><strong><font size="3">Compressive Perceptual Hashing Tracking</font></strong> [<a href="/assets/publications/Neurocomputing2017.pdf">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"><strong>Zheng Li</strong>, Long Chen, Jian-Fei Yang, <strong>Neurocomputing 2017</strong>.<br></font></p>
</li>
<li><p><strong><font size="3">Online Visual Tracking via Correlation Filter with Convolutional Networks</font></strong> [<a href="/assets/publications/VCIP2016.pdf">pdf</a>][<a href="/assets/slides/VCIP_slides.pptx">slides</a>][<a href="/assets/video/VCIP_demo.avi">demo</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"><strong>Zheng Li</strong>, Jianfei Yang, Juan Zha, Chang-Dong Wang, Weishi Zheng (<strong>VCIP 2016, Oral</strong>).<br></font></p>
</li>
<li><p><strong><font size="3">Compressive Perceptual Hashing Tracking with Online foreground learning</font></strong> [<a href="/assets/publications/ROBIO2015.pdf">pdf</a>][<a href="/assets/slides/ROBIO_slides.pptx">slides</a>][<a href="/assets/video/ROBIO_demo.mp4">demo</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"><strong>Zheng Li</strong>, Jian-Fei Yang, Long Chen, Juan Zha (<strong>ROBIO 2015, Oral</strong>).<br></font></p>
</li>
<li><p><strong><font size="3">Robust Vehicle Tracking Using Perceptual Hashing Algorithm</font></strong> [<a href="/assets/publications/ICMLA2015.pdf">pdf</a>]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2"><strong>Zheng Li</strong>, Jian-Fei Yang, Long Chen, Juan Zha (<strong>ICMLA 2015</strong>, Oral).<br></font><br>&lt;!‚Äì</p>
</li>
<li><strong><font size="3">Long-Term Revenue Maximization Pricing Scheme for Cloud</font></strong><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="2">Wen-Kai Huan, Chang-Dong Wang, Shao-Shu Huan, <strong>Zheng Li</strong>, Jian-Huang Lai, Ling Huang, (<strong>IJSSE journal 2015</strong>)<br></font><br>‚Äì&gt;</li>
</ul>
<h2 id="lt-‚ÄìProjects"><a href="#lt-‚ÄìProjects" class="headerlink" title="&lt;!‚ÄìProjects"></a>&lt;!‚Äì<font color="black" size="6">Projects</font></h2><ul>
<li><strong><font size="3">Coffee Tag Cloud</font></strong> [<a href="https://coffeedialog-tagcloud.herokuapp.com/" target="_blank" rel="external">demo</a>][<a href="/assets/data/1">sample1</a>][<a href="/assets/data/2">sample2</a>][<a href="/assets/data/3">sample3</a>]</li>
<li><strong><font size="3">Domain Attention Transfer</font></strong> [<a href="/assets/video/hatn_visualization.mp4">demo</a>]</li>
<li><strong><font size="3">Cross-Granularity Aspect-based Sentiment Analysis</font></strong> [<a href="/assets/blogImg/absa_demo.png">demo</a>]‚Äì&gt;</li>
</ul>
<h2 id="Professional-Activities"><a href="#Professional-Activities" class="headerlink" title="Professional Activities"></a><font color="black" size="6">Professional Activities</font></h2><ul>
<li>Program Organzier/Chair: KDD Cup 2023, 2024.</li>
<li>Senior Program Committee/Area Chair (Meta-Reviewer): ICLR 2026, AAAI (2023-2025), IJCAI (2021)</li>
<li>Program Committee (Reviewer): <ul>
<li>ICLR, NeurIPS, ICML, KDD, ACL, NAACL, AAAI, IJCAI (2022) </li>
<li>NeurIPS, ICLR, ACL, EMNLP, NAACL, AAAI, IJCAI (2021) </li>
<li>ACL, EMNLP, ICLR, AAAI, IJCAI (2020)</li>
</ul>
</li>
<li>Conference Secondary Reviewer: AAAI, IJCAI (2019)</li>
<li>Journal Reviewer: PAMI, TBD, Neurocomputing</li>
</ul>
<h2 id="Honors-amp-Awards"><a href="#Honors-amp-Awards" class="headerlink" title="Honors &amp; Awards"></a><font color="black" size="6">Honors &amp; Awards</font></h2><ul>
<li>Jul 2023, ACL 2023 Outstanding Paper Award</li>
<li>Nov 2018, Baidu PhD Fellowship Nomination Awards, about 20/5,000 applicants worldwide.</li>
<li>2017-2019, AAAI19, AAAI18, IJCAI17 student travel awards</li>
<li>Jun 2016, Excellent Graduates Awards, Sun Yat-sen University</li>
<li>May 2016, Excellent Undergraduate Thesis Awards, Sun Yat-sen University</li>
<li>Sep 2015, ‚ÄúYongSheng Liu‚Äù Excellent Undergraduate Scholarship</li>
<li>Sep 2015, First-class Merit Scholarship, Sun Yat-sen University</li>
<li>Aug 2015, ‚ÄúHUAWEI‚Äù Cup China Intelligent Design Competition, Second Prize</li>
<li>Sep 2014, Second-class Merit Scholarship, Sun Yat-sen University</li>
<li>Sep 2013, Third-class Merit Scholarship, Sun Yat-sen University</li>
</ul>
<h2 id="Mentorship"><a href="#Mentorship" class="headerlink" title="Mentorship  "></a><font color="black" size="6">Mentorship</font>  </h2><ul>
<li><a href="https://wjerry5.github.io/" target="_blank" rel="external">Ruijie Wang</a>, UIUC Ph.D., topic: Temporal Event Forecasting. Achievement: NeurIPS 2022, WWW 2022, WWW 2023. Now: Assistant Professor, Beihang University.</li>
<li><a href="https://zijieh.github.io/" target="_blank" rel="external">Zijie Huang</a>, UCLA Ph.D., topic: Multilingual KG Completion. Achievement: ACL 2022. Now: Research Scientist, Google DeepMind.</li>
<li><a href="https://wangpf3.github.io/" target="_blank" rel="external">Peifeng Wang</a>, USC Ph.D., topic: Self-Consistent Chain-of-Thought Distillation. Achievement: ACL 2023 Outstanding Paper Award. Now: Research Scientist, Meta.</li>
<li><a href="http://cse.msu.edu/~jinwei2/" target="_blank" rel="external">Wei Jin</a>, Michigan State University Ph.D., topic: Graph Condensation. Achievement: KDD 2022, KDD Cup 2023. Now: Assistant Professor, Emory University.</li>
<li><a href="https://fenglinliu.com/" target="_blank" rel="external">Fenglin Liu</a>, Oxford Ph.D., topic: Benchmarking LLM on Healthcare, Few-shot Product Title Generation. Achievement: ACL 2023, EMNLP 2025, Nature Review Bioengineering. Now: Applied Scientist, Amazon.</li>
<li><a href="https://cliang1453.github.io/" target="_blank" rel="external">Chen Liang</a>, Gatech Ph.D., topic: Knowledge Distillation. Achievement: ICLR 2022. Now: Senior Researcher, Microsoft.</li>
<li><a href="https://scholar.google.com/citations?user=IxrYJ6EAAAAJ&amp;hl=en" target="_blank" rel="external">Changlong Yu</a>, HKUST Ph.D., topic: Commonsense Knowledge Graph Construction. Achievement: ACL 2023, SIGMOD 2024. Now: Applied Scientist, Amazon.</li>
<li><a href="https://yifan-gao.github.io/" target="_blank" rel="external">Yifan Gao</a>, CUHK Ph.D., topic: Multilingual Keyphrase Generation. Achievement: NAACL 2022. Now: Senior Applied Scientist, Amazon.</li>
<li><a href="http://www.bjx.fun/" target="_blank" rel="external">Jiaxin Bai</a>, HKUST Ph.D., topic: Knowledge Graph Reasoning. Achievement: KDD 2023, KDD 2024.</li>
<li><a href="https://scholar.google.com/citations?user=4zli0KkAAAAJ&amp;hl=en" target="_blank" rel="external">Shiyang Li</a>, UCSB Ph.D., topic: Retrieval-Augmented Question Answering. Achievement: ACL 2023. Now: Applied Scientist, Amazon.</li>
<li><a href="https://seanliu96.github.io/" target="_blank" rel="external">Xin Liu</a>, HKUST Ph.D., topic: Session-based Recommendation. Achievement: NeurIPS 2023, SIGMOD 2024. Now: Senior Applied Scientist, Amazon.</li>
<li><a href="https://layneins.github.io/" target="_blank" rel="external">Hui Liu</a>, HKUST Ph.D., topic: Knowledge-Selective Pretraining for Attribute Value Extraction. Achievement: EMNLP 2023. Now: Applied Scientist, Amazon.</li>
<li><a href="https://vickizeng.com/" target="_blank" rel="external">Qi Zeng</a>, UIUC Ph.D., topic: Document Summarization. Achievement: EMNLP 2023. Now: Research Scientist, Meta.</li>
<li><a href="https://scholar.google.com/citations?user=y3yJm98AAAAJ&amp;hl=zh-CN" target="_blank" rel="external">Yilun Jin</a>, HKUST Ph.D., topic: Comprehensive Benchmark of Large Language Models for E-Commerce Applications. Achievement: KDD Cup 2024.</li>
<li><a href="https://scholar.google.ca/citations?user=JqGAil4AAAAJ&amp;hl=en" target="_blank" rel="external">Xiusi Chen</a>, UCLA Ph.D., topic: Iterative Constitutional Alignment of Large Language Models. Achievement: NAACL 2024.</li>
<li><a href="https://binghe2727.github.io/" target="_blank" rel="external">Bing He</a>, Gatech Ph.D., topic: Hierarchical Classification. Achievement: WWW 2024. Now: Applied Scientist, Amazon.</li>
<li><a href="https://peterjin.me/" target="_blank" rel="external">Bowen Jin</a>, UIUC Ph.D. student, topic: Semantic ID Generation by Large Language Model.</li>
<li><a href="https://yuwang.org/" target="_blank" rel="external">Yu Wang</a>, UCSD Ph.D. student, topic: Emulating Human Memory: Towards Autonomous, Lifelong Learning Large Language Model.</li>
<li><a href="https://jeffhj.github.io/" target="_blank" rel="external">Jie Huang</a>, UIUC Ph.D., topic: Explainable Complementary Concept Generation in E-Commerce. Now: Research Scientist, xAI.</li>
<li><a href="https://enyandai.github.io/publication/" target="_blank" rel="external">Enyan Dai</a>, Penn State Ph.D., topic: Event Extraction. Now: Assistant Professor, HKUST.</li>
<li><a href="https://sites.google.com/view/yujia" target="_blank" rel="external">Yujia Xie</a>, Gatech Ph.D., topic: Extreme Multi-label Classification. Achievement: Amazon Post-internship Fellowship. Now: Principal Researcher, Microsoft.</li>
<li><a href="https://xutan.me/" target="_blank" rel="external">Xutang Peng</a>, University of Sheffield Ph.D., topic: Multilingual KG Pretraining.</li>
<li><a href="https://ahxt.github.io/" target="_blank" rel="external">Xiaotian Han</a>, Texas A&amp;M Ph.D., topic: Large Language Model Evaluation. Now: Applied Scientist, Amazon.</li>
<li><a href="https://scholar.google.com/citations?user=1HZGSB8AAAAJ&amp;hl=zh-CN" target="_blank" rel="external">Kewei Cheng</a>, UCLA Ph.D., topic: Can Large Language Models (LLMs) Generalize a Model based on Few-shot Examples? Now: Applied Scientist, Amazon.</li>
<li><a href="https://zhaoxuan.info/" target="_blank" rel="external">Zhaoxuan Tan</a>, University of Notre Dame Ph.D. student, topic: LLM for Personalization.</li>
<li><a href="https://fengranmark.github.io/" target="_blank" rel="external">Fengran Mo</a>, Universit√© de Montr√©al Ph.D. student.</li>
<li><a href="https://alexfan.cn/" target="_blank" rel="external">Fan Wei</a>, HKUST Ph.D. student, topic: Hierarchical RL for Deep Researcher.</li>
<li><a href="https://yaof20.github.io/" target="_blank" rel="external">Feng Yao</a>, UCSD Ph.D. student, topic: Async RL Training Infra.</li>
<li><a href="https://yupenghou.com/" target="_blank" rel="external">Yupeng Hou</a>, UCSD Ph.D. student, topic: Reasoning Tokenization.</li>
</ul>

      
    </div>
    <div class="article-info article-info-index">
      
      
      
      

      <div class="clearfix"></div>
    </div>
  </div>
</article>










  
  


      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2025 Zheng (Jackie) Li
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: false,
		animate: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		root: "/",
		innerArchive: false
	}
</script>

<script src="/./main.js"></script>


    
<div class="tools-col">
  <ul class="btn-wrap">
    
    
    
    
  </ul>
  <div class="tools-wrap">
    

    

    

    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>